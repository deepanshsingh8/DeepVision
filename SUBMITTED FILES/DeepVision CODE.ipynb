{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEPVISION CELL TRACKING CHALLENGE\n",
    "\n",
    "## COMP 9517 PROJECT\n",
    "TEAM: Deepansh, Ujjwal, Leonard, Luke, Tyson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "import pandas as pd\n",
    "from scipy.ndimage import label\n",
    "import sys\n",
    "import collections\n",
    "from scipy.spatial import distance as dist\n",
    "from collections import OrderedDict\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from predict_dataset import predict_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN THE FOLLOWING CODE BLOCKS FOR DATASET-2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_boxes(color_img,image,labels, minArea=1):       \n",
    "    conts=[]    \n",
    "    contours=[]\n",
    "    centers = []\n",
    "    radiuses = {}\n",
    "    for label in np.unique(labels):\n",
    "        # if the label is zero, we are examining the 'background'\n",
    "        # so simply ignore it\n",
    "        if label == 0:\n",
    "            continue\n",
    "        # otherwise, allocate memory for the label region and draw\n",
    "        # it on the mask\n",
    "        mask = np.zeros(image.shape, dtype=\"uint8\")\n",
    "        mask[labels == label] = 255\n",
    "        # detect contours in the mask and grab the largest one\n",
    "        cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
    "            cv2.CHAIN_APPROX_NONE)[-2]\n",
    "        \n",
    "        for i in range(len(cnts)):\n",
    "            if len(cnts[i]) >= 5 and cv2.contourArea(cnts[i]) >= minArea:\n",
    "                ellipse=cv2.fitEllipse(cnts[i])\n",
    "                (x, y), (MA, ma), angle=ellipse\n",
    "                center = (int(x), int(y))\n",
    "                centers.append(center)\n",
    "                radiuses[center] = ma\n",
    "                #cv2.drawContours(thresh,contours,-1,(150,10,255),3)\n",
    "                #cv2.drawContours(thresh,contours,-1,(150,10,255),3)\n",
    "                \n",
    "                cv2.drawContours(color_img, cnts, -1, (255,0,0), 2, 1)\n",
    "                cv2.drawContours(image, cnts, -1, (128,128,128), 2, 1)\n",
    "                contours.append(ellipse)\n",
    "\n",
    "    ################################################################################\n",
    "\n",
    "    return image,color_img,radiuses,centers\n",
    "def remove_background(image,back_img):\n",
    "    h,w = image.shape\n",
    "    output = np.zeros((h,w),dtype = \"uint8\")\n",
    "    output = np.subtract(image,back_img)\n",
    "    return output\n",
    "def apply_watershed(img):\n",
    "    img_array = img.copy()\n",
    "    distance = ndi.distance_transform_edt(img_array)\n",
    "    markers = ndi.label(peak_local_max(distance, min_distance = 10,footprint = np.ones((11, 11)), indices = False, labels = img_array))[0]\n",
    "    ws_labels = watershed(-distance, markers, mask = img_array)\n",
    "    print(\"[INFO] {} unique segments found\".format(len(np.unique(ws_labels)) - 1))\n",
    "    return ws_labels,markers\n",
    "def segmentation_try_1(frame,gray):\n",
    "        image = frame.copy()\n",
    "        #applying min_max filtering\n",
    "        #frame = run_algo(gray, filter_size,M)\n",
    "        kernel_erosion = np.ones((3,3),np.uint8)\n",
    "        erosion = cv2.erode(gray,kernel_erosion,iterations = 1)\n",
    "        kernel_dilation = np.ones((5,5), np.uint8)\n",
    "        img_dilation = cv2.dilate(erosion, kernel_dilation, iterations=1)\n",
    "        th = cv2.adaptiveThreshold(img_dilation,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "        frame = remove_background(th,img_dilation)\n",
    "        blur = cv2.GaussianBlur(frame,(5,5),0)\n",
    "        ret,th = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        frame = cv2.bitwise_not(th)\n",
    "        \n",
    "        kernel_erosion = np.ones((2,2),np.uint8)\n",
    "        frame = cv2.erode(frame,kernel_erosion,iterations = 4)\n",
    "        \n",
    "        #frame = frst(frame,2,2,0.25,0.25)\n",
    "        label,markers = cv2.connectedComponents(frame)\n",
    "       # print(\"labels\",label)\n",
    "       # print(\"markers\",markers)\n",
    "        #pd.DataFrame(markers).to_csv(\"markers.csv\")\n",
    "        #pd.DataFrame(label).to_csv(\"labels.csv\")\n",
    "        frame_boxes,color_img,radiuses,centers = make_boxes(image,frame,markers)\n",
    "        return color_img,frame_boxes,markers,radiuses,centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_try_3(frame):\n",
    "        image = frame.copy()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "                \n",
    "        filtersize = (5,5)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT,filtersize)\n",
    "        frame = cv2.erode(frame, kernel, iterations=1)\n",
    "        \n",
    "        filtersize = (3,3)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT,filtersize)\n",
    "\n",
    "\n",
    "        th = cv2.morphologyEx(frame,cv2.MORPH_TOPHAT,kernel)\n",
    "\n",
    "        \n",
    "        thresh = cv2.adaptiveThreshold(th,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "        \n",
    "        \n",
    "        gf = gaussian_filter(th,3)\n",
    "        \n",
    "        sub = cv2.subtract(gf,3)\n",
    "        frame = cv2.dilate(sub, kernel, iterations=1)\n",
    "\n",
    "        frame_thresh = np.where(frame < 1,sub,255)\n",
    "        \n",
    "\n",
    "        return frame_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CentroidTracker():\n",
    "    def __init__(self, cellID, maxDisappeared=10):\n",
    "        # initialize the next unique object ID along with two ordered\n",
    "        # dictionaries used to keep track of mapping a given object\n",
    "        # ID to its centroid and number of consecutive frames it has\n",
    "        # been marked as \"disappeared\", respectively\n",
    "        self.nextObjectID = 1\n",
    "        self.objects = OrderedDict()\n",
    "        self.disappeared = OrderedDict()\n",
    "        \n",
    "        self.colors = OrderedDict()\n",
    "        self.coords = OrderedDict()\n",
    "        self.info = OrderedDict()\n",
    "        self.selCell = cellID;\n",
    "\n",
    "        # store the number of maximum consecutive frames a given\n",
    "        # object is allowed to be marked as \"disappeared\" until we\n",
    "        # need to deregister the object from tracking\n",
    "        self.maxDisappeared = maxDisappeared\n",
    "\n",
    "    def register(self, centroid):\n",
    "        \n",
    "        # when registering an object we use the next available object\n",
    "        # ID to store the centroid\n",
    "        self.objects[self.nextObjectID] = centroid\n",
    "        self.disappeared[self.nextObjectID] = 0\n",
    "        \n",
    "        self.colors[self.nextObjectID] = tuple(np.random.choice(range(256), size=3))\n",
    "        \n",
    "        coord_list = list()\n",
    "        coord_list.append(centroid)\n",
    "        self.coords[self.nextObjectID] = coord_list\n",
    "        \n",
    "        cell_info = {'speed': 0.0, 'tDist': 0.0, 'nDist': 0.0, 'ratio': 0.0}\n",
    "        self.info[self.nextObjectID] = cell_info\n",
    "        \n",
    "        self.nextObjectID += 1\n",
    "        \n",
    "    def deregister(self, objectID):\n",
    "        # to deregister an object ID we delete the object ID from\n",
    "        # both of our respective dictionaries\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "        del self.colors[objectID]\n",
    "        del self.coords[objectID]\n",
    "        del self.info[objectID]\n",
    "\n",
    "    def update(self, inputCentroids):\n",
    "        # check to see if the list of input bounding box rectangles\n",
    "        # is empty\n",
    "        if len(inputCentroids) == 0:\n",
    "            # loop over any existing tracked objects and mark them\n",
    "            # as disappeared\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "\n",
    "                # if we have reached a maximum number of consecutive\n",
    "                # frames where a given object has been marked as\n",
    "                # missing, deregister it\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "\n",
    "            # return early as there are no centroids or tracking info\n",
    "            # to update\n",
    "            return self.objects\n",
    "\n",
    "        # initialize an array of input centroids for the current frame\n",
    "        #inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "\n",
    "        # loop over the bounding box rectangles\n",
    "#         for (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "#             # use the bounding box coordinates to derive the centroid\n",
    "#             cX = int((startX + endX) / 2.0)\n",
    "#             cY = int((startY + endY) / 2.0)\n",
    "#             inputCentroids[i] = (cX, cY)\n",
    "\n",
    "        # if we are currently not tracking any objects take the input\n",
    "        # centroids and register each of them\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(0, len(inputCentroids)):\n",
    "                self.register(inputCentroids[i])\n",
    "        # otherwise, are are currently tracking objects so we need to\n",
    "        # try to match the input centroids to existing object\n",
    "        # centroids\n",
    "        else:\n",
    "            # grab the set of object IDs and corresponding centroids\n",
    "            objectIDs = list(self.objects.keys())\n",
    "            objectCentroids = list(self.objects.values())\n",
    "\n",
    "            # compute the distance between each pair of object\n",
    "            # centroids and input centroids, respectively -- our\n",
    "            # goal will be to match an input centroid to an existing\n",
    "            # object centroid\n",
    "            D = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
    "\n",
    "            # in order to perform this matching we must (1) find the\n",
    "            # smallest value in each row and then (2) sort the row\n",
    "            # indexes based on their minimum values so that the row\n",
    "            # with the smallest value as at the *front* of the index\n",
    "            # list\n",
    "            rows = D.min(axis=1).argsort()\n",
    "\n",
    "            # next, we perform a similar process on the columns by\n",
    "            # finding the smallest value in each column and then\n",
    "            # sorting using the previously computed row index list\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "\n",
    "            # in order to determine if we need to update, register,\n",
    "            # or deregister an object we need to keep track of which\n",
    "            # of the rows and column indexes we have already examined\n",
    "            usedRows = set()\n",
    "            usedCols = set()\n",
    "\n",
    "            # loop over the combination of the (row, column) index\n",
    "            # tuples\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                # if we have already examined either the row or\n",
    "                # column value before, ignore it\n",
    "                # val\n",
    "                if row in usedRows or col in usedCols:\n",
    "                    continue\n",
    "\n",
    "                # otherwise, grab the object ID for the current row,\n",
    "                # set its new centroid, and reset the disappeared\n",
    "                # counter\n",
    "                objectID = objectIDs[row]\n",
    "                \n",
    "     ###############Task 3           \n",
    "                # calculate distance between previous and current\n",
    "                # coords and update cell info\n",
    "                path_dist = cv2.norm(np.subtract(self.objects[objectID], inputCentroids[col]))\n",
    "                norm_dist = cv2.norm(np.subtract(self.coords[objectID][0], inputCentroids[col]))\n",
    "                self.info[objectID]['speed'] = path_dist\n",
    "                self.info[objectID]['tDist'] += path_dist\n",
    "                self.info[objectID]['nDist'] = norm_dist\n",
    "                if (norm_dist != 0):\n",
    "                    self.info[objectID]['ratio'] = self.info[objectID]['tDist']/norm_dist\n",
    "    ###############         \n",
    "                \n",
    "                self.objects[objectID] = inputCentroids[col]\n",
    "                self.coords[objectID].append(inputCentroids[col])\n",
    "                self.disappeared[objectID] = 0\n",
    "\n",
    "                # indicate that we have examined each of the row and\n",
    "                # column indexes, respectively\n",
    "                usedRows.add(row)\n",
    "                usedCols.add(col)\n",
    "\n",
    "            # compute both the row and column index we have NOT yet\n",
    "            # examined\n",
    "            unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "            unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "\n",
    "            # in the event that the number of object centroids is\n",
    "            # equal or greater than the number of input centroids\n",
    "            # we need to check and see if some of these objects have\n",
    "            # potentially disappeared\n",
    "            if D.shape[0] >= D.shape[1]:\n",
    "                # loop over the unused row indexes\n",
    "                for row in unusedRows:\n",
    "                    # grab the object ID for the corresponding row\n",
    "                    # index and increment the disappeared counter\n",
    "                    objectID = objectIDs[row]\n",
    "                    self.disappeared[objectID] += 1\n",
    "\n",
    "                    # check to see if the number of consecutive\n",
    "                    # frames the object has been marked \"disappeared\"\n",
    "                    # for warrants deregistering the object\n",
    "                    if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                        self.deregister(objectID)\n",
    "\n",
    "            # otherwise, if the number of input centroids is greater\n",
    "            # than the number of existing object centroids we need to\n",
    "            # register each new input centroid as a trackable object\n",
    "            else:\n",
    "                for col in unusedCols:\n",
    "                    self.register(inputCentroids[col])\n",
    "        \n",
    "        #######task 3\n",
    "        if self.selCell != \"0\":\n",
    "            index = int(self.selCell)\n",
    "            if index in self.info:\n",
    "                info = \"\\nCell ID {}\\n speed: {}\\n tDist: {}\\n nDist: {}\\n ratio: {}\\n\".format(index, self.info[index]['speed'], self.info[index]['tDist'],self.info[index]['nDist'],self.info[index]['ratio'])           \n",
    "                print(info)\n",
    "        ######\n",
    "        # return the set of trackable objects\n",
    "        return self.objects\n",
    "    \n",
    "    def get_color(self, objectID):\n",
    "        return self.colors[objectID]\n",
    "    def get_coord(self, objectID):\n",
    "        return self.coords[objectID]\n",
    "    def get_selcell(self):\n",
    "        return int(self.selCell)\n",
    "    def set_selcell(self, cellID):\n",
    "        self.selCell = cellID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_line(image, coord1, coord2, color):\n",
    "    cv2.line(image, (int(coord1[0]), int(coord1[1])), (int(coord2[0]), int(coord2[1])) , color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mitosis_detection(Black,segmentation_try_1_img,inputCentroids,radiuses):\n",
    "    kernel = np.ones((2,2),np.uint8)\n",
    "    tmp = cv2.erode(Black, kernel, iterations = 2)\n",
    "    dividing_cells = set()\n",
    "\n",
    "    tmp_contours = cv2.findContours(tmp, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[-2]\n",
    "    tmp_centers = []\n",
    "\n",
    "    for contour in tmp_contours:\n",
    "        (x,y), radius = cv2.minEnclosingCircle(contour)\n",
    "        center = (int(x), int(y))\n",
    "        tmp_centers.append(center)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    E_distances = dist.cdist(tmp_centers, tmp_centers, metric='euclidean')\n",
    "    for x in range(len(E_distances)):\n",
    "        for y in range(len(E_distances)):\n",
    "            if E_distances[x][y] < 20 and x != y:\n",
    "                point_1 = tmp_centers[x]\n",
    "                point_2 = tmp_centers[y]\n",
    "                dividing_cells.add(point_1)\n",
    "                dividing_cells.add(point_2)\n",
    "\n",
    "    dividing_centers = set()\n",
    "    for center in dividing_cells:\n",
    "        for x in inputCentroids:\n",
    "            dist1 = math.sqrt((x[0]-center[0])**2 + (x[1]-center[1])**2)\n",
    "            if dist1 < radiuses[x]:\n",
    "                dividing_centers.add(x)\n",
    "                cv2.ellipse(segmentation_try_1_img, (int(x[0]), int(x[1])), (20,15), 0, 0, 360, (0,0,255), 2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mouse_click(event, x,y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        ct = param[0]\n",
    "        obj = param[1]\n",
    "        rad = param[2]\n",
    "        for (ID, centroid) in obj.items():\n",
    "            margin = rad[centroid] if (centroid in rad and rad[centroid] > 6) else 6\n",
    "            if x > centroid[0] and x < centroid[0] + margin:\n",
    "                # if x is within x-range of centroid\n",
    "                if y > centroid[1] and y < centroid[1] + margin:\n",
    "                    # if y is also in y-range of centroid\n",
    "                    ct.set_selcell(ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN FUNCTION FOR DATASET-2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please enter cellID of cell to track, 0 if you would not like to track a cell: 2\n",
      "\n",
      "Cell ID 2\n",
      " speed: 0.0\n",
      " tDist: 0.0\n",
      " nDist: 0.0\n",
      " ratio: 0.0\n",
      "\n",
      "Frame Per Second:  1.75908047943841\n",
      "\n",
      "Cell ID 2\n",
      " speed: 70.06425622241343\n",
      " tDist: 70.06425622241343\n",
      " nDist: 70.06425622241343\n",
      " ratio: 1.0\n",
      "\n",
      "Frame Per Second:  2.717500236484429\n",
      "\n",
      "Cell ID 2\n",
      " speed: 1.0\n",
      " tDist: 71.06425622241343\n",
      " nDist: 69.06518659932803\n",
      " ratio: 1.0289446785206378\n",
      "\n",
      "Frame Per Second:  3.03255604110211\n",
      "\n",
      "Cell ID 2\n",
      " speed: 3.1622776601683795\n",
      " tDist: 74.22653388258182\n",
      " nDist: 66.12110101926616\n",
      " ratio: 1.122584662662437\n",
      "\n",
      "Frame Per Second:  2.8566396393021694\n",
      "\n",
      "Cell ID 2\n",
      " speed: 4.123105625617661\n",
      " tDist: 78.34963950819947\n",
      " nDist: 70.178344238091\n",
      " ratio: 1.1164361365150777\n",
      "\n",
      "Frame Per Second:  2.83241605000466\n",
      "\n",
      "Cell ID 2\n",
      " speed: 1.0\n",
      " tDist: 79.34963950819947\n",
      " nDist: 70.25667228100119\n",
      " ratio: 1.1294249632380782\n",
      "\n",
      "Frame Per Second:  2.889546579366523\n",
      "\n",
      "Cell ID 2\n",
      " speed: 6.324555320336759\n",
      " tDist: 85.67419482853623\n",
      " nDist: 69.05070600652827\n",
      " ratio: 1.2407432129721645\n",
      "\n",
      "Frame Per Second:  2.7395487975336703\n",
      "\n",
      "Cell ID 2\n",
      " speed: 2.23606797749979\n",
      " tDist: 87.91026280603602\n",
      " nDist: 71.19691004531025\n",
      " ratio: 1.2347482882345493\n",
      "\n",
      "Frame Per Second:  2.832427526444879\n",
      "\n",
      "Cell ID 2\n",
      " speed: 2.23606797749979\n",
      " tDist: 90.1463307835358\n",
      " nDist: 69.05070600652827\n",
      " ratio: 1.3055091829910195\n",
      "\n",
      "Frame Per Second:  2.475738166870602\n"
     ]
    }
   ],
   "source": [
    "imgs_path = \"C:/Users/Deepansh/Desktop/COMP 9517/GROUP PROJECT/images/Fluo-N2DL-HeLa/Sequence 2/t%03d.tif\"\n",
    "\n",
    "cap = cv2.VideoCapture(imgs_path)\n",
    "filter_size = 3\n",
    "selectedCell = input(\"please enter cellID of cell to track, 0 if you would not like to track a cell: \")\n",
    "ct = CentroidTracker(selectedCell)\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    start_time = time.time()\n",
    "    if (ret) :\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow(\"Frame1\", frame)\n",
    "\n",
    "        segmentation_try_1_img,Black,markers,radiuses,inputCentroids = segmentation_try_1(frame,gray)\n",
    "\n",
    "        mitosis_detection(Black,segmentation_try_1_img,inputCentroids,radiuses)\n",
    "        objects = ct.update(inputCentroids)\n",
    "        for (objectID, centroid) in objects.items():\n",
    "        # draw both the ID of the object and the centroid of the\n",
    "        # object on the output frame\n",
    "            color = (int(ct.get_color(objectID)[1]), int(ct.get_color(objectID)[0]), int(ct.get_color(objectID)[2]))\n",
    "\n",
    "            text = \"{}\".format(objectID)\n",
    "                #print(int(centroid[1]),int(centroid[0]))\n",
    "            cv2.putText(segmentation_try_1_img, text, (int(centroid[0]), int(centroid[1])),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            cv2.circle(segmentation_try_1_img, (int(centroid[0]), int(centroid[1])), 4, color, 1)\n",
    "\n",
    "            for ind, coord in enumerate(ct.get_coord(objectID)):\n",
    "                if ind < len(ct.get_coord(objectID)) - 1:\n",
    "                    draw_line(segmentation_try_1_img, coord, ct.get_coord(objectID)[ind + 1], color)\n",
    "            \n",
    "            if ct.get_selcell() == objectID:\n",
    "                \n",
    "                cellRad = int(radiuses[centroid]) if (centroid in radiuses) else 0\n",
    "                cv2.rectangle(segmentation_try_1_img, (int(centroid[0])-cellRad, int(centroid[1])-cellRad), (int(centroid[0])+cellRad, int(centroid[1])+cellRad), (0,255,0), 2)\n",
    "\n",
    "        # show the output frame\n",
    "        cv2.imshow(\"Frame\", segmentation_try_1_img)\n",
    "        cv2.setMouseCallback(\"Frame\", get_mouse_click, [ct, objects, radiuses])\n",
    "        end_time = time.time()\n",
    "        fps = 1/(end_time - start_time)\n",
    "        print(\"Frame Per Second: \", fps)\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    else:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    # 'q' to quit playback\n",
    "    if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR DATASET -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting DIC-C2DH-HeLa and creating 8-bit thresholded binary masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_16_bit_img_to_8_bit_binary(img_path):\n",
    "    img16 = cv2.imread(img_path,-1)\n",
    "    ratio = np.amax(img16) / 256\n",
    "    img8 = (img16 / ratio).astype('uint8')\n",
    "    thres = cv2.adaptiveThreshold(img8, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,3,2)\n",
    "    background = img8 == 0\n",
    "    thres[background] = 0\n",
    "    return cv2.cvtColor(thres, cv2.COLOR_GRAY2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded images from directory C:/Users/Deepansh/Desktop/COMP 9517/GROUP PROJECT/images/DIC-C2DH-HeLa\\Sequence 3 to shape (115, 512, 512, 1)\n",
      "Model was created\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9a9cf02e8107>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msequences\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m      \u001b[0mpredict_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msequences\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\COMP 9517\\GROUP PROJECT\\DeepVision\\Final\\predict_dataset.py\u001b[0m in \u001b[0;36mpredict_dataset\u001b[1;34m(sequence, viz)\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_ni\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m     \u001b[0mpred_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pred shape: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1462\u001b[1;33m                                             callbacks=callbacks)\n\u001b[0m\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mD:\\ANACONDA\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'size'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mD:\\ANACONDA\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def convert_mask(img_path):\n",
    "    img16 = cv2.imread(img_path,-1)\n",
    "    ratio = np.amax(img16) / 256\n",
    "    img8 = (img16 / ratio).astype('uint8')\n",
    "    thres = cv2.adaptiveThreshold(img8, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,3,2)\n",
    "    background = img8 == 0\n",
    "    thres[background] = 0\n",
    "    return cv2.cvtColor(thres, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "\n",
    "DIC_path = \"C:/Users/Deepansh/Desktop/COMP 9517/GROUP PROJECT/images/DIC-C2DH-HeLa/\"\n",
    "\n",
    "sequences = [3, 4]\n",
    "\n",
    "for seq in sequences:\n",
    "     predict_dataset(sequence=seq)\n",
    "\n",
    "for seq in sequences:\n",
    "    seq_name = 'Sequence '+str(seq)+' Masks'\n",
    "    seq_name_binary = seq_name+'_binary'\n",
    "    if not os.path.isdir(os.path.join(DIC_path, seq_name_binary)):\n",
    "        os.mkdir(os.path.join(DIC_path, seq_name_binary))\n",
    "    path = os.path.join(DIC_path, seq_name)\n",
    "    for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "        for filename in os.listdir(dirpath):\n",
    "            if 'mask' in filename and '.tif' in filename:\n",
    "                src = dirpath\n",
    "                dest = src.replace('Masks', 'Masks_binary')\n",
    "                dest_img = os.path.join(dest, filename)\n",
    "                thres = convert_mask(os.path.join(src, filename))\n",
    "                cv2.imwrite(os.path.join(dest, filename), thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_boxes_DIC(color_img, image, labels, minArea):\n",
    "    print(\"Number of cells:\", len(labels))   \n",
    "    conts=[]    \n",
    "    contours=[]\n",
    "    centers = []\n",
    "    radiuses = {}\n",
    "    \n",
    "    kernel_erosion = np.ones((3,3),np.uint8)\n",
    "    image = cv2.erode(image,kernel_erosion,iterations = 2)      \n",
    "\n",
    "    for label in labels:\n",
    "        mask = (image == label) * 1 \n",
    "        cnts = cv2.findContours(mask.copy().astype('uint8'), cv2.RETR_EXTERNAL,\n",
    "            cv2.CHAIN_APPROX_NONE)[-2]\n",
    "        \n",
    "        for i in range(len(cnts)):\n",
    "            if len(cnts[i]) >= 5 and cv2.contourArea(cnts[i]) >= minArea:\n",
    "#                 print('cv2.contourArea(cnts[i])', cv2.contourArea(cnts[i]))\n",
    "                ellipse=cv2.fitEllipse(cnts[i])\n",
    "                (x, y), (MA, ma), angle=ellipse\n",
    "                center = (int(x), int(y))\n",
    "                centers.append(center)\n",
    "                radiuses[center] = ma\n",
    "                \n",
    "                cv2.drawContours(color_img, cnts, -1, (255,0,0), 2, 1)\n",
    "                cv2.drawContours(image, cnts, -1, (128,128,128), 2, 1)\n",
    "                contours.append(ellipse)\n",
    "                \n",
    "    return image,color_img,radiuses,centers\n",
    "def segmentation_try_1_DIC(frame, gray, minArea=1000):\n",
    "    labels = np.unique(gray)[1:]\n",
    "    print('labels', labels)\n",
    "    frame_boxes,color_img,radiuses,centers = make_boxes_DIC(frame,gray,labels,minArea)\n",
    "\n",
    "    return color_img,frame_boxes,labels,radiuses,centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN FUNCTION FOR DATASET-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please enter cellID of cell to track, 0 if you would not like to track a cell: 1\n",
      "labels [255]\n",
      "Number of cells: 1\n",
      "\n",
      "Cell ID 1\n",
      " speed: 0.0\n",
      " tDist: 0.0\n",
      " nDist: 0.0\n",
      " ratio: 0.0\n",
      "\n",
      "Frame Per Second:  12.533442502442858\n",
      "labels [255]\n",
      "Number of cells: 1\n",
      "\n",
      "Cell ID 1\n",
      " speed: 12.041594578792296\n",
      " tDist: 12.041594578792296\n",
      " nDist: 12.041594578792296\n",
      " ratio: 1.0\n",
      "\n",
      "Frame Per Second:  22.76617779562947\n",
      "labels [255]\n",
      "Number of cells: 1\n",
      "\n",
      "Cell ID 1\n",
      " speed: 10.04987562112089\n",
      " tDist: 22.091470199913186\n",
      " nDist: 19.697715603592208\n",
      " ratio: 1.121524477482274\n",
      "\n",
      "Frame Per Second:  23.890591981226112\n",
      "labels [255]\n",
      "Number of cells: 1\n",
      "\n",
      "Cell ID 1\n",
      " speed: 2.23606797749979\n",
      " tDist: 24.327538177412976\n",
      " nDist: 21.18962010041709\n",
      " ratio: 1.1480875099282275\n",
      "\n",
      "Frame Per Second:  21.779201694853647\n",
      "labels [255]\n",
      "Number of cells: 1\n",
      "\n",
      "Cell ID 1\n",
      " speed: 3.605551275463989\n",
      " tDist: 27.933089452876963\n",
      " nDist: 24.166091947189145\n",
      " ratio: 1.1558794659028835\n",
      "\n",
      "Frame Per Second:  21.35353473643482\n",
      "labels [255]\n",
      "Number of cells: 1\n",
      "\n",
      "Cell ID 1\n",
      " speed: 5.0\n",
      " tDist: 32.93308945287696\n",
      " nDist: 19.313207915827967\n",
      " ratio: 1.7052107343538172\n",
      "\n",
      "Frame Per Second:  20.44376422649308\n",
      "labels [255]\n",
      "Number of cells: 1\n",
      "\n",
      "Cell ID 1\n",
      " speed: 5.385164807134504\n",
      " tDist: 38.318254260011464\n",
      " nDist: 23.53720459187964\n",
      " ratio: 1.627986624768147\n",
      "\n",
      "Frame Per Second:  21.81397574320248\n",
      "labels [255]\n",
      "Number of cells: 1\n",
      "\n",
      "Cell ID 1\n",
      " speed: 10.0\n",
      " tDist: 48.318254260011464\n",
      " nDist: 15.033296378372908\n",
      " ratio: 3.2140824636120873\n",
      "\n",
      "Frame Per Second:  22.26051512851676\n",
      "labels [255]\n",
      "Number of cells: 1\n",
      "\n",
      "Cell ID 1\n",
      " speed: 22.02271554554524\n",
      " tDist: 70.34096980555671\n",
      " nDist: 35.34119409414458\n",
      " ratio: 1.990339364826696\n",
      "\n",
      "Frame Per Second:  21.797537690792584\n",
      "labels [255]\n",
      "Number of cells: 1\n",
      "\n",
      "Cell ID 1\n",
      " speed: 29.966648127543394\n",
      " tDist: 100.3076179331001\n",
      " nDist: 22.47220505424423\n",
      " ratio: 4.463630413258241\n",
      "\n",
      "Frame Per Second:  19.673095684803002\n",
      "labels [255]\n",
      "Number of cells: 1\n",
      "\n",
      "Cell ID 1\n",
      " speed: 30.528675044947494\n",
      " tDist: 130.8362929780476\n",
      " nDist: 37.69615364994153\n",
      " ratio: 3.470812810055769\n",
      "\n",
      "Frame Per Second:  21.34180023406096\n",
      "labels [255]\n",
      "Number of cells: 1\n",
      "\n",
      "Cell ID 1\n",
      " speed: 8.06225774829855\n",
      " tDist: 138.89855072634614\n",
      " nDist: 44.9221548904324\n",
      " ratio: 3.0919832555924205\n",
      "\n",
      "Frame Per Second:  20.071609392870645\n",
      "labels [255]\n",
      "Number of cells: 1\n",
      "\n",
      "Cell ID 1\n",
      " speed: 7.211102550927978\n",
      " tDist: 146.10965327727413\n",
      " nDist: 39.6232255123179\n",
      " ratio: 3.6874749944789875\n",
      "\n",
      "Frame Per Second:  21.314361504804786\n",
      "labels [255]\n",
      "Number of cells: 1\n",
      "\n",
      "Cell ID 1\n",
      " speed: 4.0\n",
      " tDist: 150.10965327727413\n",
      " nDist: 40.52159917870962\n",
      " ratio: 3.704435568183177\n",
      "\n",
      "Frame Per Second:  20.465610117885863\n",
      "labels [255]\n",
      "Number of cells: 1\n",
      "\n",
      "Cell ID 1\n",
      " speed: 7.810249675906654\n",
      " tDist: 157.91990295318078\n",
      " nDist: 44.28317965096906\n",
      " ratio: 3.566137395685519\n",
      "\n",
      "Frame Per Second:  20.036994573110142\n",
      "labels [255]\n",
      "Number of cells: 1\n",
      "\n",
      "Cell ID 1\n",
      " speed: 2.23606797749979\n",
      " tDist: 160.15597093068058\n",
      " nDist: 42.42640687119285\n",
      " ratio: 3.774912436419994\n",
      "\n",
      "Frame Per Second:  20.888280203389492\n",
      "labels [255]\n",
      "Number of cells: 1\n",
      "\n",
      "Cell ID 1\n",
      " speed: 3.0\n",
      " tDist: 163.15597093068058\n",
      " nDist: 39.45883931389772\n",
      " ratio: 4.134839588989526\n",
      "\n",
      "Frame Per Second:  22.82254229264497\n",
      "labels [255]\n",
      "Number of cells: 1\n",
      "\n",
      "Cell ID 1\n",
      " speed: 7.0710678118654755\n",
      " tDist: 170.22703874254606\n",
      " nDist: 46.52956049652737\n",
      " ratio: 3.658470807074367\n",
      "\n",
      "Frame Per Second:  23.8596060094089\n",
      "labels [255]\n",
      "Number of cells: 1\n",
      "\n",
      "Cell ID 1\n",
      " speed: 2.23606797749979\n",
      " tDist: 172.46310672004586\n",
      " nDist: 47.265209192385896\n",
      " ratio: 3.6488383245710567\n",
      "\n",
      "Frame Per Second:  22.786833055354844\n"
     ]
    }
   ],
   "source": [
    "imgs_path = \"C:/Users/Deepansh/Desktop/COMP 9517/GROUP PROJECT/images/DIC-C2DH-HeLa/Sequence 3 Masks_binary/t%03dmask.tif\"\n",
    "cap = cv2.VideoCapture(imgs_path)\n",
    "filter_size = 3\n",
    "selectedCell = input(\"please enter cellID of cell to track, 0 if you would not like to track a cell: \")\n",
    "ct = CentroidTracker(selectedCell)\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    start_time = time.time()\n",
    "    if (ret) :\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow(\"Frame1\", frame)\n",
    "#####################Section 1############            \n",
    "        \n",
    "        segmentation_try_1_img,Black,markers,radiuses,inputCentroids = segmentation_try_1_DIC(frame,gray)\n",
    "\n",
    "\n",
    "##################Tracking from centroids########################################################        \n",
    "\n",
    "    \n",
    "        mitosis_detection(Black,segmentation_try_1_img,inputCentroids,radiuses)\n",
    "        objects = ct.update(inputCentroids)\n",
    "        for (objectID, centroid) in objects.items():\n",
    "        # draw both the ID of the object and the centroid of the\n",
    "        # object on the output frame\n",
    "            color = (int(ct.get_color(objectID)[1]), int(ct.get_color(objectID)[0]), int(ct.get_color(objectID)[2]))\n",
    "\n",
    "            text = \"{}\".format(objectID)\n",
    "                #print(int(centroid[1]),int(centroid[0]))\n",
    "            cv2.putText(segmentation_try_1_img, text, (int(centroid[0]), int(centroid[1])),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            cv2.circle(segmentation_try_1_img, (int(centroid[0]), int(centroid[1])), 4, color, 1)\n",
    "\n",
    "            for ind, coord in enumerate(ct.get_coord(objectID)):\n",
    "                if ind < len(ct.get_coord(objectID)) - 1:\n",
    "                    draw_line(segmentation_try_1_img, coord, ct.get_coord(objectID)[ind + 1], color)\n",
    "            \n",
    "            if ct.get_selcell() == objectID:\n",
    "                \n",
    "                cellRad = int(radiuses[centroid]) if (centroid in radiuses) else 0\n",
    "                cv2.rectangle(segmentation_try_1_img, (int(centroid[0])-cellRad, int(centroid[1])-cellRad), (int(centroid[0])+cellRad, int(centroid[1])+cellRad), (0,255,0), 2)\n",
    "\n",
    "        # show the output frame\n",
    "        cv2.imshow(\"Frame\", segmentation_try_1_img)\n",
    "        cv2.setMouseCallback(\"Frame\", get_mouse_click, [ct, objects, radiuses])\n",
    "        end_time = time.time()\n",
    "        fps = 1/(end_time - start_time)\n",
    "        print(\"Frame Per Second: \", fps)\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    else:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    # 'q' to quit playback\n",
    "    if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
