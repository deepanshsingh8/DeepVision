{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast_strech(image):\n",
    "    a = 0\n",
    "    b = 255\n",
    "    c = image.min()\n",
    "    d_max = image.max()\n",
    "    image_new = image\n",
    "    image_new[:,:,:] = (image[:,:,:] - c)* ((b-a)/(d_max - c)) + a #(I-c)(b-a/max - min) + a\n",
    "    return image_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_max_filtered(image,N):\n",
    "    h,w = image.shape\n",
    "    output = np.zeros((h,w),dtype = np.uint8)\n",
    "    #filter_new = np.array([[1]*N]*N  ,dtype =\"int\")  ## N*N filter with 1 in all places\n",
    "    #need to pad the image according to filter size\n",
    "    p = int((N-1)/2) #paading of zeros required\n",
    "    padded_picture = cv2.copyMakeBorder(image.copy(),p,p,p,p,cv2.BORDER_CONSTANT,value = 0)\n",
    "    for y in np.arange(p,h+p):\n",
    "        for x in np.arange(p,w+p):\n",
    "                roi = padded_picture[y-p:y+p+1, x-p:x+p+1]\n",
    "                max_pixel = np.amax((roi)) #directly finding the max value from surrounding pixels and replacing it\n",
    "                output[y-p,x-p]= max_pixel\n",
    "    output = (output*255).astype(\"uint8\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_min_filtered(image,N):\n",
    "    h,w = image.shape\n",
    "    output = np.full((h,w),255,dtype = np.uint8)\n",
    "    #filter_new = np.array([[1]*N]*N  ,dtype =\"int\")  ## N*N filter with 1 in all places\n",
    "    #need to pad the image according to filter size\n",
    "    p = int((N-1)/2) #paading of zeros required\n",
    "    padded_picture = cv2.copyMakeBorder(image.copy(),p,p,p,p,cv2.BORDER_CONSTANT,value = 255)\n",
    "    \n",
    "    for y in np.arange(p,h+p):\n",
    "        for x in np.arange(p,w+p):\n",
    "                roi = padded_picture[y-p:y+p+1, x-p:x+p+1]\n",
    "                min_pixel = np.amin((roi)) #directly finding the max value from surrounding pixels and replacing it\n",
    "                output[y-p,x-p]= min_pixel\n",
    "           \n",
    "    output = (output*255).astype(\"uint8\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_background(image,back_img):\n",
    "    h,w = image.shape\n",
    "    output = np.zeros((h,w),dtype = \"uint8\")\n",
    "    output = np.subtract(image,back_img)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algo(image,filter_size, M):\n",
    "    if M == 0:\n",
    "        max_filter =  convolve_max_filtered(image,filter_size)\n",
    "        #min_filter =  convolve_min_filtered(max_filter,filter_size)\n",
    "        final_image = remove_background(image, max_filter)\n",
    "    else:\n",
    "        min_filter = convolve_min_filtered(image,filter_size)\n",
    "        #max_filter = convolve_max_filtered(min_filter,filter_size)\n",
    "        final_image = remove_background(image, min_filter)\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_watershed(img):\n",
    "    img_array = img.copy()\n",
    "    distance = ndi.distance_transform_edt(img_array)\n",
    "    markers = ndi.label(peak_local_max(distance, indices = False, labels = img_array))[0]\n",
    "    ws_labels = watershed(-distance, markers, mask = img_array)\n",
    "    print(\"[INFO] {} unique segments found\".format(len(np.unique(ws_labels)) - 1))\n",
    "    return ws_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_sharpening(image):\n",
    "    sigma = 10\n",
    "    a = 10\n",
    "    blur_image = cv2.GaussianBlur(image,(0,0),sigma)  #L = I*G\n",
    "    #H = image - blur_image #H = I - L\n",
    "    H = cv2.subtract(image,blur_image)\n",
    "    final_image = H*a + image #o = I+H*a\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_boxes(image,labels):       \n",
    "    conts=[]    \n",
    "    for label in np.unique(labels):\n",
    "        # if the label is zero, we are examining the 'background'\n",
    "        # so simply ignore it\n",
    "        if label == 0:\n",
    "            continue\n",
    "        # otherwise, allocate memory for the label region and draw\n",
    "        # it on the mask\n",
    "        mask = np.zeros(gray.shape, dtype=\"uint8\")\n",
    "        mask[labels == label] = 255\n",
    "        # detect contours in the mask and grab the largest one\n",
    "        cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
    "            cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int0(box)  \n",
    "        if cv2.contourArea(c) > 50: \n",
    "            #cv2.drawContours(image,c,-1,(0,255,0))\n",
    "            cv2.drawContours(image,[box],-1,(128,128,128),thickness = 1)      \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_try_1(frame,gray):\n",
    "        #applying min_max filtering\n",
    "        #frame = run_algo(gray, filter_size,M)\n",
    "#         kernel_erosion = np.ones((3,3),np.uint8)\n",
    "#         erosion = cv2.erode(gray,kernel_erosion,iterations = 1)\n",
    "#         kernel_dilation = np.ones((5,5), np.uint8)\n",
    "#         img_dilation = cv2.dilate(erosion, kernel_dilation, iterations=3)\n",
    "#         th = cv2.adaptiveThreshold(img_dilation,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "#         frame = remove_background(th,img_dilation)\n",
    "#         cv2.imshow('original image1',frame)\n",
    "#         blur = cv2.GaussianBlur(frame,(5,5),0)\n",
    "#         ret,th = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        frame = cv2.bitwise_not(gray)\n",
    "        label = apply_watershed(frame)\n",
    "        frame_boxes = make_boxes(frame,label)\n",
    "        return frame_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_try_2(frame,gray):\n",
    "        ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "        # noise removal\n",
    "        kernel = np.ones((3,3),np.uint8)\n",
    "        opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "        # sure background area\n",
    "        sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "        # Finding sure foreground area\n",
    "        dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "        ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "        # Finding unknown region\n",
    "        sure_fg = np.uint8(sure_fg)\n",
    "        unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "        # Marker labelling\n",
    "        ret, markers = cv2.connectedComponents(sure_fg)\n",
    "        # Add one to all labels so that sure background is not 0, but 1\n",
    "        markers = markers+1\n",
    "        # Now, mark the region of unknown with zero\n",
    "        markers[unknown==255] = 0\n",
    "        markers = cv2.watershed(frame,markers)\n",
    "        #frame_boxes = make_boxes(frame,markers)\n",
    "        frame[markers == -1] = [255,0,0]\n",
    "        return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\skimage\\morphology\\_deprecated.py:5: skimage_deprecation: Function ``watershed`` is deprecated and will be removed in version 0.19. Use ``skimage.segmentation.watershed`` instead.\n",
      "  def watershed(image, markers=None, connectivity=1, offset=None, mask=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 2380 unique segments found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\skimage\\morphology\\_deprecated.py:5: skimage_deprecation: Function ``watershed`` is deprecated and will be removed in version 0.19. Use ``skimage.segmentation.watershed`` instead.\n",
      "  def watershed(image, markers=None, connectivity=1, offset=None, mask=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 2860 unique segments found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\skimage\\morphology\\_deprecated.py:5: skimage_deprecation: Function ``watershed`` is deprecated and will be removed in version 0.19. Use ``skimage.segmentation.watershed`` instead.\n",
      "  def watershed(image, markers=None, connectivity=1, offset=None, mask=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 2902 unique segments found\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"C:/Users/Deepansh/Desktop/COMP 9517/GROUP PROJECT/images/Fluo-N2DL-HeLa/Sequence 4/t%03d.tif\")\n",
    "filter_size = 3\n",
    "M = 0\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    if (ret) :  \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('original image',gray)\n",
    "        segmentation_try_2_img = segmentation_try_2(frame,gray)\n",
    "        cv2.imshow('segmentation_try_2',segmentation_try_2_img)\n",
    "        segmentation_try_1_img = segmentation_try_1(segmentation_try_2_img,gray)\n",
    "        cv2.imshow('segmentation_try_1',segmentation_try_1_img)\n",
    "\n",
    "        time.sleep(0.5)\n",
    "    else:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    # 'q' to quit playback\n",
    "    if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
