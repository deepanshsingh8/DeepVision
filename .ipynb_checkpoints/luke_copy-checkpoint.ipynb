{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "import pandas as pd\n",
    "from scipy.ndimage import label\n",
    "import sys\n",
    "import collections\n",
    "from scipy.spatial import distance as dist\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast_strech(image):\n",
    "    a = 0\n",
    "    b = 255\n",
    "    c = image.min()\n",
    "    d_max = image.max()\n",
    "    image_new = image\n",
    "    image_new[:,:,:] = (image[:,:,:] - c)* ((b-a)/(d_max - c)) + a #(I-c)(b-a/max - min) + a\n",
    "    return image_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_max_filtered(image,N):\n",
    "    h,w = image.shape\n",
    "    output = np.zeros((h,w),dtype = np.uint8)\n",
    "    #filter_new = np.array([[1]*N]*N  ,dtype =\"int\")  ## N*N filter with 1 in all places\n",
    "    #need to pad the image according to filter size\n",
    "    p = int((N-1)/2) #paading of zeros required\n",
    "    padded_picture = cv2.copyMakeBorder(image.copy(),p,p,p,p,cv2.BORDER_CONSTANT,value = 0)\n",
    "    for y in np.arange(p,h+p):\n",
    "        for x in np.arange(p,w+p):\n",
    "                roi = padded_picture[y-p:y+p+1, x-p:x+p+1]\n",
    "                max_pixel = np.amax((roi)) #directly finding the max value from surrounding pixels and replacing it\n",
    "                output[y-p,x-p]= max_pixel\n",
    "    output = (output*255).astype(\"uint8\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_min_filtered(image,N):\n",
    "    h,w = image.shape\n",
    "    output = np.full((h,w),255,dtype = np.uint8)\n",
    "    #filter_new = np.array([[1]*N]*N  ,dtype =\"int\")  ## N*N filter with 1 in all places\n",
    "    #need to pad the image according to filter size\n",
    "    p = int((N-1)/2) #paading of zeros required\n",
    "    padded_picture = cv2.copyMakeBorder(image.copy(),p,p,p,p,cv2.BORDER_CONSTANT,value = 255)\n",
    "    \n",
    "    for y in np.arange(p,h+p):\n",
    "        for x in np.arange(p,w+p):\n",
    "                roi = padded_picture[y-p:y+p+1, x-p:x+p+1]\n",
    "                min_pixel = np.amin((roi)) #directly finding the max value from surrounding pixels and replacing it\n",
    "                output[y-p,x-p]= min_pixel\n",
    "           \n",
    "    output = (output*255).astype(\"uint8\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_background(image,back_img):\n",
    "    h,w = image.shape\n",
    "    output = np.zeros((h,w),dtype = \"uint8\")\n",
    "    output = np.subtract(image,back_img)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algo(image,filter_size, M):\n",
    "    if M == 0:\n",
    "        max_filter =  convolve_max_filtered(image,filter_size)\n",
    "        #min_filter =  convolve_min_filtered(max_filter,filter_size)\n",
    "        final_image = remove_background(image, max_filter)\n",
    "    else:\n",
    "        min_filter = convolve_min_filtered(image,filter_size)\n",
    "        #max_filter = convolve_max_filtered(min_filter,filter_size)\n",
    "        final_image = remove_background(image, min_filter)\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_watershed(img):\n",
    "    img_array = img.copy()\n",
    "    distance = ndi.distance_transform_edt(img_array)\n",
    "    markers = ndi.label(peak_local_max(distance, min_distance = 10,footprint = np.ones((11, 11)), indices = False, labels = img_array))[0]\n",
    "    ws_labels = watershed(-distance, markers, mask = img_array)\n",
    "    print(\"[INFO] {} unique segments found\".format(len(np.unique(ws_labels)) - 1))\n",
    "    return ws_labels,markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_sharpening(image):\n",
    "    sigma = 10\n",
    "    a = 10\n",
    "    blur_image = cv2.GaussianBlur(image,(0,0),sigma)  #L = I*G\n",
    "    #H = image - blur_image #H = I - L\n",
    "    H = cv2.subtract(image,blur_image)\n",
    "    final_image = H*a + image #o = I+H*a\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradx(img):\n",
    "    img = img.astype('int')\n",
    "    rows, cols = img.shape\n",
    "    # Use hstack to add back in the columns that were dropped as zeros\n",
    "    return np.hstack( (np.zeros((rows, 1)), (img[:, 2:] - img[:, :-2])/2.0, np.zeros((rows, 1))) )\n",
    "\n",
    "def grady(img):\n",
    "    img = img.astype('int')\n",
    "    rows, cols = img.shape\n",
    "    # Use vstack to add back the rows that were dropped as zeros\n",
    "    return np.vstack( (np.zeros((1, cols)), (img[2:, :] - img[:-2, :])/2.0, np.zeros((1, cols))) )\n",
    "\n",
    "#Performs fast radial symmetry transform\n",
    "#img: input image, grayscale\n",
    "#radii: integer value for radius size in pixels (n in the original paper); also used to size gaussian kernel\n",
    "#alpha: Strictness of symmetry transform (higher=more strict; 2 is good place to start)\n",
    "#beta: gradient threshold parameter, float in [0,1]\n",
    "#stdFactor: Standard deviation factor for gaussian kernel\n",
    "#mode: BRIGHT, DARK, or BOTH\n",
    "def frst(img, radii, alpha, beta, stdFactor, mode='BOTH'):\n",
    "    mode = mode.upper()\n",
    "    assert mode in ['BRIGHT', 'DARK', 'BOTH']\n",
    "    dark = (mode == 'DARK' or mode == 'BOTH')\n",
    "    bright = (mode == 'BRIGHT' or mode == 'BOTH')\n",
    "\n",
    "    workingDims = tuple((e + 2*radii) for e in img.shape)\n",
    "\n",
    "    #Set up output and M and O working matrices\n",
    "    output = np.zeros(img.shape, np.uint8)\n",
    "    O_n = np.zeros(workingDims, np.int16)\n",
    "    M_n = np.zeros(workingDims, np.int16)\n",
    "\n",
    "    #Calculate gradients\n",
    "    gx = gradx(img)\n",
    "    gy = grady(img)\n",
    "\n",
    "    #Find gradient vector magnitude\n",
    "    gnorms = np.sqrt( np.add( np.multiply(gx, gx) , np.multiply(gy, gy) ) )\n",
    "\n",
    "    #Use beta to set threshold - speeds up transform significantly\n",
    "    gthresh = np.amax(gnorms)*beta\n",
    "\n",
    "    #Find x/y distance to affected pixels\n",
    "    gpx = np.multiply(np.divide(gx, gnorms, out=np.zeros(gx.shape), where=gnorms!=0), radii).round().astype(int);\n",
    "    gpy = np.multiply(np.divide(gy, gnorms, out=np.zeros(gy.shape), where=gnorms!=0), radii).round().astype(int);\n",
    "\n",
    "    #Iterate over all pixels (w/ gradient above threshold)\n",
    "    for coords, gnorm in np.ndenumerate(gnorms):\n",
    "        if gnorm > gthresh:\n",
    "            i, j = coords\n",
    "            #Positively affected pixel\n",
    "            if bright:\n",
    "                ppve = (i+gpx[i,j], j+gpy[i,j])\n",
    "                O_n[ppve] += 1\n",
    "                M_n[ppve] += gnorm\n",
    "            #Negatively affected pixel\n",
    "            if dark:\n",
    "                pnve = (i-gpx[i,j], j-gpy[i,j])\n",
    "                O_n[pnve] -= 1\n",
    "                M_n[pnve] -= gnorm\n",
    "\n",
    "    #Abs and normalize O matrix\n",
    "    O_n = np.abs(O_n)\n",
    "    O_n = O_n / float(np.amax(O_n))\n",
    "\n",
    "    #Normalize M matrix\n",
    "    M_max = float(np.amax(np.abs(M_n)))\n",
    "    M_n = M_n / M_max\n",
    "\n",
    "    #Elementwise multiplication\n",
    "    F_n = np.multiply(np.power(O_n, alpha), M_n)\n",
    "\n",
    "    #Gaussian blur\n",
    "    kSize = int( np.ceil( radii / 2 ) )\n",
    "    kSize = kSize + 1 if kSize % 2 == 0 else kSize\n",
    "\n",
    "    S = cv2.GaussianBlur(F_n, (kSize, kSize), int( radii * stdFactor ))\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_try_2(frame,gray):\n",
    "        ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "        # noise removal\n",
    "        kernel = np.ones((3,3),np.uint8)\n",
    "        opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "        # sure background area\n",
    "        sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "        # Finding sure foreground area\n",
    "        dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "        ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "        # Finding unknown region\n",
    "        sure_fg = np.uint8(sure_fg)\n",
    "        unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "        # Marker labelling\n",
    "        ret, markers = cv2.connectedComponents(sure_fg)\n",
    "        # Add one to all labels so that sure background is not 0, but 1\n",
    "        markers = markers+1\n",
    "        # Now, mark the region of unknown with zero\n",
    "        markers[unknown==255] = 0\n",
    "        markers = cv2.watershed(frame,markers)\n",
    "        #frame_boxes = make_boxes(frame,markers)\n",
    "        frame[markers == -1] = [255,0,0]\n",
    "        df = pd.DataFrame(markers)\n",
    "        df.to_csv(\"markers.csv\")\n",
    "        return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_boxes(color_img,image,labels):       \n",
    "    conts=[]    \n",
    "    contours=[]\n",
    "    for label in np.unique(labels):\n",
    "        # if the label is zero, we are examining the 'background'\n",
    "        # so simply ignore it\n",
    "        if label == 0:\n",
    "            continue\n",
    "        # otherwise, allocate memory for the label region and draw\n",
    "        # it on the mask\n",
    "        mask = np.zeros(gray.shape, dtype=\"uint8\")\n",
    "        mask[labels == label] = 255\n",
    "        # detect contours in the mask and grab the largest one\n",
    "        cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
    "            cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "        \n",
    "#         rect = cv2.minAreaRect(c)\n",
    "#         box = cv2.boxPoints(rect)\n",
    "#         box = np.int0(box)  \n",
    "#         if cv2.contourArea(c) > 50: \n",
    "#             #cv2.drawContours(image,c,-1,(0,255,0))\n",
    "#             cv2.drawContours(image,[box],-1,(128,128,128),thickness = 1)\n",
    "        hull = cv2.convexHull(c)\n",
    "        #cv2.drawContours(image,[hull],-1,(0,0,255),thickness = 1)\n",
    "        contours.append(hull)\n",
    "    for i in range(len(contours)):\n",
    "        c = contours[i]\n",
    "\n",
    "        area = cv2.contourArea(c)\n",
    "\n",
    "        # Iterate all contours from i+1 to end of list\n",
    "        for j in range(i+1, len(contours)):\n",
    "            c2 = contours[j]\n",
    "\n",
    "            area2 = cv2.contourArea(c2)\n",
    "\n",
    "            area_sum = area + area2\n",
    "\n",
    "            # Merge contours together\n",
    "            tmp = np.vstack((c, c2))\n",
    "            merged_c = cv2.convexHull(tmp)\n",
    "\n",
    "            merged_area = cv2.contourArea(merged_c)\n",
    "\n",
    "            # Replace contours c and c2 by the convex hull of merged c and c2, if total area is increased by no more then 10%\n",
    "            if merged_area < area_sum*1.1:\n",
    "                # Replace contour with merged one.\n",
    "                contours[i] = merged_c\n",
    "                contours[j] = merged_c\n",
    "                c = merged_c\n",
    "                area = merged_area\n",
    "    ################################################################################\n",
    "\n",
    "\n",
    "    # Draw new contours in red color\n",
    "    for c in contours:\n",
    "        #Ignore small contours\n",
    "        if cv2.contourArea(c) > 20:\n",
    "            cv2.drawContours(color_img, [c], -1, (255,255,0), 2, 1)\n",
    "            cv2.drawContours(image, [c], -1, (128,128,128), 2, 1)\n",
    "    return image,color_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_try_1(frame,gray):\n",
    "        image = frame.copy()\n",
    "        #applying min_max filtering\n",
    "        #frame = run_algo(gray, filter_size,M)\n",
    "        kernel_erosion = np.ones((3,3),np.uint8)\n",
    "        erosion = cv2.erode(gray,kernel_erosion,iterations = 1)\n",
    "        kernel_dilation = np.ones((5,5), np.uint8)\n",
    "        img_dilation = cv2.dilate(erosion, kernel_dilation, iterations=1)\n",
    "        th = cv2.adaptiveThreshold(img_dilation,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "        frame = remove_background(th,img_dilation)\n",
    "        blur = cv2.GaussianBlur(frame,(5,5),0)\n",
    "        ret,th = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        frame = cv2.bitwise_not(th)\n",
    "        #frame = frst(frame,2,2,0.25,0.25)\n",
    "        label,markers = apply_watershed(frame)\n",
    "       # print(\"labels\",label)\n",
    "       # print(\"markers\",markers)\n",
    "        #pd.DataFrame(markers).to_csv(\"markers.csv\")\n",
    "        #pd.DataFrame(label).to_csv(\"labels.csv\")\n",
    "        frame_boxes,color_img = make_boxes(image,frame,label)\n",
    "        return color_img,frame_boxes,markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_on_dt(a, img):\n",
    "    border = cv2.dilate(img, None, iterations=5)\n",
    "    border = border - cv2.erode(border, None)\n",
    "\n",
    "    dt = cv2.distanceTransform(img, 2, 3)\n",
    "    dt = ((dt - dt.min()) / (dt.max() - dt.min()) * 255).astype(np.uint8)\n",
    "    _, dt = cv2.threshold(dt, 180, 255, cv2.THRESH_BINARY)\n",
    "    lbl, ncc = label(dt)\n",
    "    lbl = lbl * (255 / (ncc + 1))\n",
    "    # Completing the markers now. \n",
    "    lbl[border == 255] = 255\n",
    "\n",
    "    lbl = lbl.astype(np.int32)\n",
    "    cv2.watershed(a, lbl)\n",
    "\n",
    "    lbl[lbl == -1] = 0\n",
    "    lbl = lbl.astype(np.uint8)\n",
    "    return 255 - lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_different(img,img_gray):\n",
    "    _, img_bin = cv2.threshold(img_gray, 0, 255,\n",
    "            cv2.THRESH_OTSU)\n",
    "    img_bin = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN,\n",
    "            np.ones((3, 3), dtype=int))\n",
    "    cv2.imshow(\"morph\",img_bin)\n",
    "    result = segment_on_dt(img, img_bin)\n",
    "    result[result != 255] = 0\n",
    "    result = cv2.dilate(result, None)\n",
    "    img[result == 255] = (0, 0, 255)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroid(markers):\n",
    "\n",
    "    markers = pd.DataFrame(markers)\n",
    "    markers.drop(markers.columns[[0]],axis=1,inplace=True)\n",
    "    all_point_dict = collections.defaultdict(list)\n",
    "    centroid_dict = collections.defaultdict(list)\n",
    "\n",
    "    for i,row in markers.iterrows():\n",
    "        for j, val in enumerate(row):\n",
    "            all_point_dict[val].append([i,j])\n",
    "        #break\n",
    "\n",
    "            #a[markers.iloc[i,j]].append([i,j])\n",
    "\n",
    "    for key in all_point_dict:\n",
    "        if key == 0:\n",
    "            continue\n",
    "        else:\n",
    "            if len(all_point_dict[key])%2 == 0:\n",
    "                centroid_dict[key] = all_point_dict[key][int(len(all_point_dict[key])/2)-1]\n",
    "            else:\n",
    "                centroid_dict[key] = all_point_dict[key][int((len(all_point_dict[key])+1)/2)-1]\n",
    "                \n",
    "    centrelist = list()\n",
    "    for key,value in centroid_dict.items():\n",
    "        centrelist.append(value)\n",
    "                \n",
    "    return centrelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CentroidTracker():\n",
    "    def __init__(self, maxDisappeared=3):\n",
    "        # initialize the next unique object ID along with two ordered\n",
    "        # dictionaries used to keep track of mapping a given object\n",
    "        # ID to its centroid and number of consecutive frames it has\n",
    "        # been marked as \"disappeared\", respectively\n",
    "        self.nextObjectID = 1\n",
    "        self.objects = OrderedDict()\n",
    "        self.disappeared = OrderedDict()\n",
    "        \n",
    "        self.colors = OrderedDict()\n",
    "        self.coords = OrderedDict()\n",
    "\n",
    "        # store the number of maximum consecutive frames a given\n",
    "        # object is allowed to be marked as \"disappeared\" until we\n",
    "        # need to deregister the object from tracking\n",
    "        self.maxDisappeared = maxDisappeared\n",
    "\n",
    "    def register(self, centroid):\n",
    "        \n",
    "        # when registering an object we use the next available object\n",
    "        # ID to store the centroid\n",
    "        self.objects[self.nextObjectID] = centroid\n",
    "        self.disappeared[self.nextObjectID] = 0\n",
    "        \n",
    "        self.colors[self.nextObjectID] = tuple(np.random.choice(range(256), size=3))\n",
    "        \n",
    "        coord_list = list()\n",
    "        coord_list.append(centroid)\n",
    "        self.coords[self.nextObjectID] = coord_list\n",
    "        self.nextObjectID += 1\n",
    "        \n",
    "    def deregister(self, objectID):\n",
    "        # to deregister an object ID we delete the object ID from\n",
    "        # both of our respective dictionaries\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "        del self.colors[objectID]\n",
    "        del self.coords[objectID]\n",
    "\n",
    "    def update(self, inputCentroids):\n",
    "        # check to see if the list of input bounding box rectangles\n",
    "        # is empty\n",
    "        if len(inputCentroids) == 0:\n",
    "            # loop over any existing tracked objects and mark them\n",
    "            # as disappeared\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "\n",
    "                # if we have reached a maximum number of consecutive\n",
    "                # frames where a given object has been marked as\n",
    "                # missing, deregister it\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "\n",
    "            # return early as there are no centroids or tracking info\n",
    "            # to update\n",
    "            return self.objects\n",
    "\n",
    "        # initialize an array of input centroids for the current frame\n",
    "        #inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "\n",
    "        # loop over the bounding box rectangles\n",
    "#         for (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "#             # use the bounding box coordinates to derive the centroid\n",
    "#             cX = int((startX + endX) / 2.0)\n",
    "#             cY = int((startY + endY) / 2.0)\n",
    "#             inputCentroids[i] = (cX, cY)\n",
    "\n",
    "        # if we are currently not tracking any objects take the input\n",
    "        # centroids and register each of them\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(0, len(inputCentroids)):\n",
    "                self.register(inputCentroids[i])\n",
    "        # otherwise, are are currently tracking objects so we need to\n",
    "        # try to match the input centroids to existing object\n",
    "        # centroids\n",
    "        else:\n",
    "            # grab the set of object IDs and corresponding centroids\n",
    "            objectIDs = list(self.objects.keys())\n",
    "            objectCentroids = list(self.objects.values())\n",
    "\n",
    "            # compute the distance between each pair of object\n",
    "            # centroids and input centroids, respectively -- our\n",
    "            # goal will be to match an input centroid to an existing\n",
    "            # object centroid\n",
    "            D = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
    "\n",
    "            # in order to perform this matching we must (1) find the\n",
    "            # smallest value in each row and then (2) sort the row\n",
    "            # indexes based on their minimum values so that the row\n",
    "            # with the smallest value as at the *front* of the index\n",
    "            # list\n",
    "            rows = D.min(axis=1).argsort()\n",
    "\n",
    "            # next, we perform a similar process on the columns by\n",
    "            # finding the smallest value in each column and then\n",
    "            # sorting using the previously computed row index list\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "\n",
    "            # in order to determine if we need to update, register,\n",
    "            # or deregister an object we need to keep track of which\n",
    "            # of the rows and column indexes we have already examined\n",
    "            usedRows = set()\n",
    "            usedCols = set()\n",
    "\n",
    "            # loop over the combination of the (row, column) index\n",
    "            # tuples\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                # if we have already examined either the row or\n",
    "                # column value before, ignore it\n",
    "                # val\n",
    "                if row in usedRows or col in usedCols:\n",
    "                    continue\n",
    "\n",
    "                # otherwise, grab the object ID for the current row,\n",
    "                # set its new centroid, and reset the disappeared\n",
    "                # counter\n",
    "                objectID = objectIDs[row]\n",
    "                self.objects[objectID] = inputCentroids[col]\n",
    "                self.coords[objectID].append(inputCentroids[col])\n",
    "                self.disappeared[objectID] = 0\n",
    "\n",
    "                # indicate that we have examined each of the row and\n",
    "                # column indexes, respectively\n",
    "                usedRows.add(row)\n",
    "                usedCols.add(col)\n",
    "\n",
    "            # compute both the row and column index we have NOT yet\n",
    "            # examined\n",
    "            unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "            unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "\n",
    "            # in the event that the number of object centroids is\n",
    "            # equal or greater than the number of input centroids\n",
    "            # we need to check and see if some of these objects have\n",
    "            # potentially disappeared\n",
    "            if D.shape[0] >= D.shape[1]:\n",
    "                # loop over the unused row indexes\n",
    "                for row in unusedRows:\n",
    "                    # grab the object ID for the corresponding row\n",
    "                    # index and increment the disappeared counter\n",
    "                    objectID = objectIDs[row]\n",
    "                    self.disappeared[objectID] += 1\n",
    "\n",
    "                    # check to see if the number of consecutive\n",
    "                    # frames the object has been marked \"disappeared\"\n",
    "                    # for warrants deregistering the object\n",
    "                    if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                        self.deregister(objectID)\n",
    "\n",
    "            # otherwise, if the number of input centroids is greater\n",
    "            # than the number of existing object centroids we need to\n",
    "            # register each new input centroid as a trackable object\n",
    "            else:\n",
    "                for col in unusedCols:\n",
    "                    self.register(inputCentroids[col])\n",
    "\n",
    "        # return the set of trackable objects\n",
    "        return self.objects\n",
    "    \n",
    "    def get_color(self, objectID):\n",
    "        return self.colors[objectID]\n",
    "    def get_coord(self, objectID):\n",
    "        return self.coords[objectID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_line(image, coord1, coord2, color):\n",
    "    cv2.line(image, (coord1[1], coord1[0]), (coord2[1], coord2[0]) , color)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 46 unique segments found\n",
      "[INFO] 50 unique segments found\n",
      "[INFO] 43 unique segments found\n",
      "[INFO] 47 unique segments found\n",
      "[INFO] 53 unique segments found\n",
      "[INFO] 55 unique segments found\n",
      "[INFO] 59 unique segments found\n",
      "[INFO] 51 unique segments found\n",
      "[INFO] 72 unique segments found\n",
      "[INFO] 70 unique segments found\n",
      "[INFO] 66 unique segments found\n",
      "[INFO] 77 unique segments found\n",
      "[INFO] 63 unique segments found\n",
      "[INFO] 69 unique segments found\n",
      "[INFO] 71 unique segments found\n",
      "[INFO] 65 unique segments found\n",
      "[INFO] 74 unique segments found\n",
      "[INFO] 76 unique segments found\n",
      "[INFO] 71 unique segments found\n",
      "[INFO] 71 unique segments found\n",
      "[INFO] 73 unique segments found\n",
      "[INFO] 70 unique segments found\n",
      "[INFO] 76 unique segments found\n",
      "[INFO] 77 unique segments found\n",
      "[INFO] 85 unique segments found\n",
      "[INFO] 96 unique segments found\n",
      "[INFO] 101 unique segments found\n",
      "[INFO] 94 unique segments found\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"../../proj1/images/Fluo-N2DL-HeLa/Sequence 3/t%03d.tif\")\n",
    "filter_size = 3\n",
    "M = 0\n",
    "ct = CentroidTracker()\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    if (ret) :  \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('original image',gray)\n",
    "        \n",
    "        #pre_img = preprocessing_different(frame,gray)\n",
    "        #cv2.imshow(\"pre_img\",pre_img)\n",
    "        segmentation_try_1_img,Black,markers = segmentation_try_1(frame,gray)\n",
    "        \n",
    "        #Colored Image\n",
    "        #cv2.imshow('segmentation_try_1',segmentation_try_1_img)\n",
    "        #Black Image\n",
    "        #cv2.imshow('black and white',Black)\n",
    "        \n",
    "        \n",
    "        #segmentation_try_2_img = segmentation_try_2(frame,gray)\n",
    "        #cv2.imshow('segmentation_try_2',segmentation_try_2_img)\n",
    "        \n",
    "        \n",
    "        \n",
    "        inputCentroids = find_centroid(markers)\n",
    "       # print(\"HuLaHu\",inputCentroids[18],inputCentroids[19])q\n",
    "        \n",
    "        objects = ct.update(inputCentroids)\n",
    "        \n",
    "        for (objectID, centroid) in objects.items():\n",
    "        # draw both the ID of the object and the centroid of the\n",
    "        # object on the output frame\n",
    "            color = (int(ct.get_color(objectID)[0]), int(ct.get_color(objectID)[1]), int(ct.get_color(objectID)[2]))\n",
    "\n",
    "            text = \"ID {}\".format(objectID)\n",
    "            cv2.putText(segmentation_try_1_img, text, (centroid[1], centroid[0]),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "            \n",
    "            cv2.circle(segmentation_try_1_img, (centroid[1], centroid[0]), 4, color, 1)\n",
    "            \n",
    "            for ind, coord in enumerate(ct.get_coord(objectID)):\n",
    "                if ind < len(ct.get_coord(objectID)) - 1:\n",
    "                    draw_line(segmentation_try_1_img, coord, ct.get_coord(objectID)[ind + 1], color)\n",
    "\n",
    "        # show the output frame\n",
    "        cv2.imshow(\"Frame\", segmentation_try_1_img)\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "    else:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    # 'q' to quit playback\n",
    "    if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
