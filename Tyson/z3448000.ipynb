{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "import pandas as pd\n",
    "from scipy.ndimage import label\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_background(image,back_img):\n",
    "    h,w = image.shape\n",
    "    output = np.zeros((h,w),dtype = \"uint8\")\n",
    "    output = np.subtract(image,back_img)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_watershed(img):\n",
    "    img_array = img.copy()\n",
    "    distance = ndi.distance_transform_edt(img_array)\n",
    "    markers = ndi.label(peak_local_max(distance, indices = False, labels = img_array))[0]\n",
    "    ws_labels = watershed(-distance, markers, mask = img_array)\n",
    "    print(\"[INFO] {} unique segments found\".format(len(np.unique(ws_labels)) - 1))\n",
    "    return ws_labels,markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_boxes(color_img,image,labels):       \n",
    "    conts=[]    \n",
    "    contours=[]\n",
    "    for label in np.unique(labels):\n",
    "        # if the label is zero, we are examining the 'background'\n",
    "        # so simply ignore it\n",
    "        if label == 0:\n",
    "            continue\n",
    "        # otherwise, allocate memory for the label region and draw\n",
    "        # it on the mask\n",
    "        mask = np.zeros(gray.shape, dtype=\"uint8\")\n",
    "        mask[labels == label] = 255\n",
    "        # detect contours in the mask and grab the largest one\n",
    "        cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
    "            cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "        \n",
    "#         rect = cv2.minAreaRect(c)\n",
    "#         box = cv2.boxPoints(rect)\n",
    "#         box = np.int0(box)  \n",
    "#         if cv2.contourArea(c) > 50: \n",
    "#             #cv2.drawContours(image,c,-1,(0,255,0))\n",
    "#             cv2.drawContours(image,[box],-1,(128,128,128),thickness = 1)\n",
    "        hull = cv2.convexHull(c)\n",
    "        #cv2.drawContours(image,[hull],-1,(0,0,255),thickness = 1)\n",
    "        contours.append(hull)\n",
    "    for i in range(len(contours)):\n",
    "        c = contours[i]\n",
    "\n",
    "        area = cv2.contourArea(c)\n",
    "\n",
    "        # Iterate all contours from i+1 to end of list\n",
    "        for j in range(i+1, len(contours)):\n",
    "            c2 = contours[j]\n",
    "\n",
    "            area2 = cv2.contourArea(c2)\n",
    "\n",
    "            area_sum = area + area2\n",
    "\n",
    "            # Merge contours together\n",
    "            tmp = np.vstack((c, c2))\n",
    "            merged_c = cv2.convexHull(tmp)\n",
    "\n",
    "            merged_area = cv2.contourArea(merged_c)\n",
    "\n",
    "            # Replace contours c and c2 by the convex hull of merged c and c2, if total area is increased by no more then 10%\n",
    "            if merged_area < area_sum*1.1:\n",
    "                # Replace contour with merged one.\n",
    "                contours[i] = merged_c\n",
    "                contours[j] = merged_c\n",
    "                c = merged_c\n",
    "                area = merged_area\n",
    "    ################################################################################\n",
    "\n",
    "\n",
    "    # Draw new contours in red color\n",
    "    for c in contours:\n",
    "        #Ignore small contours\n",
    "        if cv2.contourArea(c) > 20:\n",
    "            cv2.drawContours(color_img, [c], -1, (255,0,0), 2, 1)\n",
    "            cv2.drawContours(image, [c], -1, (128,128,128), 2, 1)\n",
    "    return image,color_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_try_1(frame,gray):\n",
    "        image = frame.copy()\n",
    "        #applying min_max filtering\n",
    "        kernel_erosion = np.ones((3,3),np.uint8)\n",
    "        erosion = cv2.erode(gray,kernel_erosion,iterations = 1)\n",
    "        kernel_dilation = np.ones((5,5), np.uint8)\n",
    "        img_dilation = cv2.dilate(erosion, kernel_dilation, iterations=1)\n",
    "        th = cv2.adaptiveThreshold(img_dilation,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "        frame = remove_background(th,img_dilation)\n",
    "        blur = cv2.GaussianBlur(frame,(5,5),0)\n",
    "        ret,th = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        frame = cv2.bitwise_not(th)\n",
    "        #frame = frst(frame,2,2,0.25,0.25)\n",
    "        label,markers = apply_watershed(frame)\n",
    "       # print(\"labels\",label)\n",
    "       # print(\"markers\",markers)\n",
    "       # pd.DataFrame(markers).to_csv(\"markers.csv\")\n",
    "       # pd.DataFrame(label).to_csv(\"labels.csv\")\n",
    "        frame_boxes,color_img = make_boxes(image,frame,label)\n",
    "        return color_img,frame_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the above using 1 image only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = r'./COMP9517_Images/PhC-C2DL-PSC/Sequence 4/t001.tif'\n",
    "img = cv2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 189 unique segments found\n",
      "[INFO] 179 unique segments found\n",
      "[INFO] 188 unique segments found\n",
      "[INFO] 190 unique segments found\n",
      "[INFO] 191 unique segments found\n",
      "[INFO] 191 unique segments found\n",
      "[INFO] 187 unique segments found\n",
      "[INFO] 194 unique segments found\n",
      "[INFO] 192 unique segments found\n",
      "[INFO] 209 unique segments found\n",
      "[INFO] 186 unique segments found\n",
      "[INFO] 189 unique segments found\n",
      "[INFO] 194 unique segments found\n",
      "[INFO] 192 unique segments found\n",
      "[INFO] 190 unique segments found\n",
      "[INFO] 196 unique segments found\n",
      "[INFO] 189 unique segments found\n",
      "[INFO] 182 unique segments found\n",
      "[INFO] 188 unique segments found\n",
      "[INFO] 186 unique segments found\n",
      "[INFO] 192 unique segments found\n",
      "[INFO] 180 unique segments found\n",
      "[INFO] 203 unique segments found\n",
      "[INFO] 211 unique segments found\n",
      "[INFO] 216 unique segments found\n",
      "[INFO] 204 unique segments found\n",
      "[INFO] 192 unique segments found\n",
      "[INFO] 194 unique segments found\n",
      "[INFO] 219 unique segments found\n",
      "[INFO] 208 unique segments found\n",
      "[INFO] 196 unique segments found\n",
      "[INFO] 201 unique segments found\n",
      "[INFO] 210 unique segments found\n",
      "[INFO] 202 unique segments found\n",
      "[INFO] 199 unique segments found\n",
      "[INFO] 216 unique segments found\n",
      "[INFO] 228 unique segments found\n",
      "[INFO] 240 unique segments found\n",
      "[INFO] 227 unique segments found\n",
      "[INFO] 237 unique segments found\n",
      "[INFO] 236 unique segments found\n",
      "[INFO] 243 unique segments found\n",
      "[INFO] 238 unique segments found\n",
      "[INFO] 243 unique segments found\n",
      "[INFO] 239 unique segments found\n",
      "[INFO] 253 unique segments found\n",
      "[INFO] 228 unique segments found\n",
      "[INFO] 236 unique segments found\n",
      "[INFO] 239 unique segments found\n",
      "[INFO] 234 unique segments found\n",
      "[INFO] 241 unique segments found\n",
      "[INFO] 241 unique segments found\n",
      "[INFO] 242 unique segments found\n",
      "[INFO] 244 unique segments found\n",
      "[INFO] 249 unique segments found\n",
      "[INFO] 250 unique segments found\n",
      "[INFO] 258 unique segments found\n",
      "[INFO] 253 unique segments found\n",
      "[INFO] 259 unique segments found\n",
      "[INFO] 247 unique segments found\n",
      "[INFO] 241 unique segments found\n",
      "[INFO] 245 unique segments found\n",
      "[INFO] 252 unique segments found\n",
      "[INFO] 256 unique segments found\n",
      "[INFO] 258 unique segments found\n",
      "[INFO] 245 unique segments found\n",
      "[INFO] 264 unique segments found\n",
      "[INFO] 277 unique segments found\n",
      "[INFO] 281 unique segments found\n",
      "[INFO] 267 unique segments found\n",
      "[INFO] 274 unique segments found\n",
      "[INFO] 275 unique segments found\n",
      "[INFO] 286 unique segments found\n",
      "[INFO] 279 unique segments found\n",
      "[INFO] 286 unique segments found\n",
      "[INFO] 288 unique segments found\n",
      "[INFO] 279 unique segments found\n",
      "[INFO] 294 unique segments found\n",
      "[INFO] 284 unique segments found\n",
      "[INFO] 282 unique segments found\n",
      "[INFO] 301 unique segments found\n",
      "[INFO] 286 unique segments found\n",
      "[INFO] 307 unique segments found\n",
      "[INFO] 300 unique segments found\n",
      "[INFO] 319 unique segments found\n",
      "[INFO] 342 unique segments found\n",
      "[INFO] 339 unique segments found\n",
      "[INFO] 319 unique segments found\n",
      "[INFO] 300 unique segments found\n",
      "[INFO] 292 unique segments found\n",
      "[INFO] 283 unique segments found\n",
      "[INFO] 317 unique segments found\n",
      "[INFO] 294 unique segments found\n",
      "[INFO] 284 unique segments found\n",
      "[INFO] 284 unique segments found\n",
      "[INFO] 314 unique segments found\n",
      "[INFO] 312 unique segments found\n",
      "[INFO] 294 unique segments found\n",
      "[INFO] 307 unique segments found\n",
      "[INFO] 317 unique segments found\n",
      "[INFO] 316 unique segments found\n",
      "[INFO] 308 unique segments found\n",
      "[INFO] 303 unique segments found\n",
      "[INFO] 323 unique segments found\n",
      "[INFO] 320 unique segments found\n",
      "[INFO] 324 unique segments found\n",
      "[INFO] 332 unique segments found\n",
      "[INFO] 331 unique segments found\n",
      "[INFO] 353 unique segments found\n",
      "[INFO] 334 unique segments found\n",
      "[INFO] 346 unique segments found\n",
      "[INFO] 334 unique segments found\n",
      "[INFO] 338 unique segments found\n",
      "[INFO] 346 unique segments found\n",
      "[INFO] 345 unique segments found\n",
      "[INFO] 346 unique segments found\n",
      "[INFO] 330 unique segments found\n",
      "[INFO] 326 unique segments found\n",
      "[INFO] 339 unique segments found\n",
      "[INFO] 330 unique segments found\n",
      "[INFO] 334 unique segments found\n",
      "[INFO] 336 unique segments found\n",
      "[INFO] 343 unique segments found\n",
      "[INFO] 349 unique segments found\n",
      "[INFO] 353 unique segments found\n",
      "[INFO] 341 unique segments found\n",
      "[INFO] 343 unique segments found\n",
      "[INFO] 352 unique segments found\n",
      "[INFO] 339 unique segments found\n",
      "[INFO] 331 unique segments found\n",
      "[INFO] 348 unique segments found\n",
      "[INFO] 338 unique segments found\n",
      "[INFO] 330 unique segments found\n",
      "[INFO] 334 unique segments found\n",
      "[INFO] 336 unique segments found\n",
      "[INFO] 336 unique segments found\n",
      "[INFO] 340 unique segments found\n",
      "[INFO] 356 unique segments found\n",
      "[INFO] 346 unique segments found\n",
      "[INFO] 328 unique segments found\n",
      "[INFO] 347 unique segments found\n",
      "[INFO] 326 unique segments found\n",
      "[INFO] 344 unique segments found\n",
      "[INFO] 353 unique segments found\n",
      "[INFO] 384 unique segments found\n",
      "[INFO] 389 unique segments found\n",
      "[INFO] 396 unique segments found\n",
      "[INFO] 389 unique segments found\n",
      "[INFO] 389 unique segments found\n",
      "[INFO] 378 unique segments found\n",
      "[INFO] 400 unique segments found\n",
      "[INFO] 382 unique segments found\n",
      "[INFO] 374 unique segments found\n",
      "[INFO] 409 unique segments found\n",
      "[INFO] 437 unique segments found\n",
      "[INFO] 433 unique segments found\n",
      "[INFO] 432 unique segments found\n",
      "[INFO] 423 unique segments found\n",
      "[INFO] 436 unique segments found\n",
      "[INFO] 439 unique segments found\n",
      "[INFO] 416 unique segments found\n",
      "[INFO] 441 unique segments found\n",
      "[INFO] 431 unique segments found\n",
      "[INFO] 444 unique segments found\n",
      "[INFO] 453 unique segments found\n",
      "[INFO] 454 unique segments found\n",
      "[INFO] 436 unique segments found\n",
      "[INFO] 455 unique segments found\n",
      "[INFO] 468 unique segments found\n",
      "[INFO] 461 unique segments found\n",
      "[INFO] 449 unique segments found\n",
      "[INFO] 442 unique segments found\n",
      "[INFO] 457 unique segments found\n",
      "[INFO] 457 unique segments found\n",
      "[INFO] 449 unique segments found\n",
      "[INFO] 496 unique segments found\n",
      "[INFO] 477 unique segments found\n",
      "[INFO] 473 unique segments found\n",
      "[INFO] 473 unique segments found\n",
      "[INFO] 474 unique segments found\n",
      "[INFO] 492 unique segments found\n",
      "[INFO] 491 unique segments found\n",
      "[INFO] 505 unique segments found\n",
      "[INFO] 503 unique segments found\n",
      "[INFO] 493 unique segments found\n",
      "[INFO] 497 unique segments found\n",
      "[INFO] 498 unique segments found\n",
      "[INFO] 502 unique segments found\n",
      "[INFO] 510 unique segments found\n",
      "[INFO] 515 unique segments found\n",
      "[INFO] 526 unique segments found\n",
      "[INFO] 535 unique segments found\n",
      "[INFO] 516 unique segments found\n",
      "[INFO] 536 unique segments found\n",
      "[INFO] 529 unique segments found\n",
      "[INFO] 567 unique segments found\n",
      "[INFO] 557 unique segments found\n",
      "[INFO] 566 unique segments found\n",
      "[INFO] 527 unique segments found\n",
      "[INFO] 546 unique segments found\n",
      "[INFO] 549 unique segments found\n",
      "[INFO] 545 unique segments found\n",
      "[INFO] 556 unique segments found\n",
      "[INFO] 552 unique segments found\n",
      "[INFO] 566 unique segments found\n",
      "[INFO] 556 unique segments found\n",
      "[INFO] 573 unique segments found\n",
      "[INFO] 593 unique segments found\n",
      "[INFO] 573 unique segments found\n",
      "[INFO] 608 unique segments found\n",
      "[INFO] 606 unique segments found\n",
      "[INFO] 641 unique segments found\n",
      "[INFO] 657 unique segments found\n",
      "[INFO] 663 unique segments found\n",
      "[INFO] 650 unique segments found\n",
      "[INFO] 646 unique segments found\n",
      "[INFO] 678 unique segments found\n",
      "[INFO] 681 unique segments found\n",
      "[INFO] 682 unique segments found\n",
      "[INFO] 668 unique segments found\n",
      "[INFO] 708 unique segments found\n",
      "[INFO] 721 unique segments found\n",
      "[INFO] 716 unique segments found\n",
      "[INFO] 715 unique segments found\n",
      "[INFO] 737 unique segments found\n",
      "[INFO] 718 unique segments found\n",
      "[INFO] 730 unique segments found\n",
      "[INFO] 716 unique segments found\n",
      "[INFO] 736 unique segments found\n",
      "[INFO] 734 unique segments found\n",
      "[INFO] 762 unique segments found\n",
      "[INFO] 770 unique segments found\n",
      "[INFO] 770 unique segments found\n",
      "[INFO] 777 unique segments found\n",
      "[INFO] 774 unique segments found\n",
      "[INFO] 774 unique segments found\n",
      "[INFO] 788 unique segments found\n",
      "[INFO] 775 unique segments found\n",
      "[INFO] 787 unique segments found\n",
      "[INFO] 799 unique segments found\n",
      "[INFO] 815 unique segments found\n",
      "[INFO] 788 unique segments found\n",
      "[INFO] 817 unique segments found\n",
      "[INFO] 854 unique segments found\n",
      "[INFO] 830 unique segments found\n",
      "[INFO] 858 unique segments found\n",
      "[INFO] 849 unique segments found\n",
      "[INFO] 874 unique segments found\n",
      "[INFO] 884 unique segments found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 881 unique segments found\n",
      "[INFO] 905 unique segments found\n",
      "[INFO] 910 unique segments found\n",
      "[INFO] 910 unique segments found\n",
      "[INFO] 914 unique segments found\n",
      "[INFO] 942 unique segments found\n",
      "[INFO] 946 unique segments found\n",
      "[INFO] 956 unique segments found\n",
      "[INFO] 923 unique segments found\n",
      "[INFO] 937 unique segments found\n",
      "[INFO] 948 unique segments found\n",
      "[INFO] 982 unique segments found\n",
      "[INFO] 965 unique segments found\n",
      "[INFO] 997 unique segments found\n",
      "[INFO] 1012 unique segments found\n",
      "[INFO] 1007 unique segments found\n",
      "[INFO] 1013 unique segments found\n",
      "[INFO] 1013 unique segments found\n",
      "[INFO] 1043 unique segments found\n",
      "[INFO] 1011 unique segments found\n",
      "[INFO] 1042 unique segments found\n",
      "[INFO] 1052 unique segments found\n",
      "[INFO] 1037 unique segments found\n",
      "[INFO] 1033 unique segments found\n",
      "[INFO] 1019 unique segments found\n",
      "[INFO] 1043 unique segments found\n",
      "[INFO] 1044 unique segments found\n",
      "[INFO] 1035 unique segments found\n",
      "[INFO] 1047 unique segments found\n",
      "[INFO] 1059 unique segments found\n",
      "[INFO] 1062 unique segments found\n",
      "[INFO] 1094 unique segments found\n",
      "[INFO] 1064 unique segments found\n",
      "[INFO] 1060 unique segments found\n",
      "[INFO] 1050 unique segments found\n",
      "[INFO] 1081 unique segments found\n",
      "[INFO] 1153 unique segments found\n",
      "[INFO] 1150 unique segments found\n",
      "[INFO] 1171 unique segments found\n",
      "[INFO] 1187 unique segments found\n",
      "[INFO] 1178 unique segments found\n",
      "[INFO] 1160 unique segments found\n",
      "[INFO] 1175 unique segments found\n",
      "[INFO] 1190 unique segments found\n",
      "[INFO] 1206 unique segments found\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-8254c65e6dad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m#pre_img = preprocessing_different(frame,gray)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m#cv2.imshow(\"pre_img\",pre_img)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0msegmentation_try_1_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBlack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msegmentation_try_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-32ccb711ee8c>\u001b[0m in \u001b[0;36msegmentation_try_1\u001b[1;34m(frame, gray)\u001b[0m\n\u001b[0;32m     18\u001b[0m        \u001b[1;31m# pd.DataFrame(markers).to_csv(\"markers.csv\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m        \u001b[1;31m# pd.DataFrame(label).to_csv(\"labels.csv\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mframe_boxes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_boxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcolor_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe_boxes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-c94805be291f>\u001b[0m in \u001b[0;36mmake_boxes\u001b[1;34m(color_img, image, labels)\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;31m# Merge contours together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0mmerged_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvexHull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mmerged_area\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontourArea\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"./COMP9517_Images/PhC-C2DL-PSC/Sequence 4/t%03d.tif\")\n",
    "filter_size = 3\n",
    "M = 0\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    if (ret) :  \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('original image',gray)\n",
    "        \n",
    "        segmentation_try_1_img,Black = segmentation_try_1(frame,gray)\n",
    "        \n",
    "        \n",
    "        #Colored Image\n",
    "        cv2.imshow('segmentation_try_1',segmentation_try_1_img)\n",
    "        #Black Image\n",
    "        cv2.imshow('black and white',Black)\n",
    "        \n",
    "        #ct.update()\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "        \n",
    "    else:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    # 'q' to quit playback\n",
    "    if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONT RUN FROM HERE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CentroidTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from scipy.spatial import distance as dist\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "class CentroidTracker():\n",
    "    def __init__(self, maxDisappeared=50):\n",
    "        # initialize the next unique object ID along with two ordered\n",
    "        # dictionaries used to keep track of mapping a given object\n",
    "        # ID to its centroid and number of consecutive frames it has\n",
    "        # been marked as \"disappeared\", respectively\n",
    "        self.nextObjectID = 0\n",
    "        self.objects = OrderedDict()\n",
    "        self.disappeared = OrderedDict()\n",
    "\n",
    "        # store the number of maximum consecutive frames a given\n",
    "        # object is allowed to be marked as \"disappeared\" until we\n",
    "        # need to deregister the object from tracking\n",
    "        self.maxDisappeared = maxDisappeared\n",
    "\n",
    "    def register(self, centroid):\n",
    "        # when registering an object we use the next available object\n",
    "        # ID to store the centroid\n",
    "        self.objects[self.nextObjectID] = centroid\n",
    "        self.disappeared[self.nextObjectID] = 0\n",
    "        self.nextObjectID += 1\n",
    "\n",
    "    def deregister(self, objectID):\n",
    "        # to deregister an object ID we delete the object ID from\n",
    "        # both of our respective dictionaries\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "\n",
    "    def update(self, rects):\n",
    "        # check to see if the list of input bounding box rectangles\n",
    "        # is empty\n",
    "        if len(rects) == 0:\n",
    "            # loop over any existing tracked objects and mark them\n",
    "            # as disappeared\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "\n",
    "                # if we have reached a maximum number of consecutive\n",
    "                # frames where a given object has been marked as\n",
    "                # missing, deregister it\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "\n",
    "            # return early as there are no centroids or tracking info\n",
    "            # to update\n",
    "            return self.objects\n",
    "\n",
    "        # initialize an array of input centroids for the current frame\n",
    "        inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "\n",
    "        # loop over the bounding box rectangles\n",
    "        for (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "            # use the bounding box coordinates to derive the centroid\n",
    "            cX = int((startX + endX) / 2.0)\n",
    "            cY = int((startY + endY) / 2.0)\n",
    "            inputCentroids[i] = (cX, cY)\n",
    "\n",
    "        # if we are currently not tracking any objects take the input\n",
    "        # centroids and register each of them\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(0, len(inputCentroids)):\n",
    "                self.register(inputCentroids[i])\n",
    "\n",
    "        # otherwise, are are currently tracking objects so we need to\n",
    "        # try to match the input centroids to existing object\n",
    "        # centroids\n",
    "        else:\n",
    "            # grab the set of object IDs and corresponding centroids\n",
    "            objectIDs = list(self.objects.keys())\n",
    "            objectCentroids = list(self.objects.values())\n",
    "\n",
    "            # compute the distance between each pair of object\n",
    "            # centroids and input centroids, respectively -- our\n",
    "            # goal will be to match an input centroid to an existing\n",
    "            # object centroid\n",
    "            D = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
    "\n",
    "            # in order to perform this matching we must (1) find the\n",
    "            # smallest value in each row and then (2) sort the row\n",
    "            # indexes based on their minimum values so that the row\n",
    "            # with the smallest value as at the *front* of the index\n",
    "            # list\n",
    "            rows = D.min(axis=1).argsort()\n",
    "\n",
    "            # next, we perform a similar process on the columns by\n",
    "            # finding the smallest value in each column and then\n",
    "            # sorting using the previously computed row index list\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "\n",
    "            # in order to determine if we need to update, register,\n",
    "            # or deregister an object we need to keep track of which\n",
    "            # of the rows and column indexes we have already examined\n",
    "            usedRows = set()\n",
    "            usedCols = set()\n",
    "\n",
    "            # loop over the combination of the (row, column) index\n",
    "            # tuples\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                # if we have already examined either the row or\n",
    "                # column value before, ignore it\n",
    "                # val\n",
    "                if row in usedRows or col in usedCols:\n",
    "                    continue\n",
    "\n",
    "                # otherwise, grab the object ID for the current row,\n",
    "                # set its new centroid, and reset the disappeared\n",
    "                # counter\n",
    "                objectID = objectIDs[row]\n",
    "                self.objects[objectID] = inputCentroids[col]\n",
    "                self.disappeared[objectID] = 0\n",
    "\n",
    "                # indicate that we have examined each of the row and\n",
    "                # column indexes, respectively\n",
    "                usedRows.add(row)\n",
    "                usedCols.add(col)\n",
    "\n",
    "            # compute both the row and column index we have NOT yet\n",
    "            # examined\n",
    "            unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "            unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "\n",
    "            # in the event that the number of object centroids is\n",
    "            # equal or greater than the number of input centroids\n",
    "            # we need to check and see if some of these objects have\n",
    "            # potentially disappeared\n",
    "            if D.shape[0] >= D.shape[1]:\n",
    "                # loop over the unused row indexes\n",
    "                for row in unusedRows:\n",
    "                    # grab the object ID for the corresponding row\n",
    "                    # index and increment the disappeared counter\n",
    "                    objectID = objectIDs[row]\n",
    "                    self.disappeared[objectID] += 1\n",
    "\n",
    "                    # check to see if the number of consecutive\n",
    "                    # frames the object has been marked \"disappeared\"\n",
    "                    # for warrants deregistering the object\n",
    "                    if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                        self.deregister(objectID)\n",
    "\n",
    "            # otherwise, if the number of input centroids is greater\n",
    "            # than the number of existing object centroids we need to\n",
    "            # register each new input centroid as a trackable object\n",
    "            else:\n",
    "                for col in unusedCols:\n",
    "                    self.register(inputCentroids[col])\n",
    "\n",
    "        # return the set of trackable objects\n",
    "        return self.objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
